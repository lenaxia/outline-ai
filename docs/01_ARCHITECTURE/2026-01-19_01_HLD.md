# Outline AI Assistant - High-Level Design

## System Overview

A Go-based service that provides three main capabilities for Outline knowledge bases:

1. **Command-Driven Filing**: On-demand document categorization and filing via `/ai-file` command
2. **Interactive Q&A**: Answers questions using workspace context (works on free-tier Outline)
3. **Content Enhancement**: Improves titles, adds summaries, and generates search terms

## Architecture Diagram

```
┌─────────────────────────────────────────────────────────────────┐
│                         Main Service                            │
│                                                                 │
│  ┌─────────────────────────────────────────┐                   │
│  │      Webhook Receiver (Primary)         │                   │
│  │   POST /webhooks - documents.update     │                   │
│  │   • Signature validation                │                   │
│  │   • Event filtering                     │                   │
│  └────────────────┬────────────────────────┘                   │
│                   │                                            │
│  ┌────────────────▼────────────────┐                           │
│  │  Fallback Polling (Optional)    │                           │
│  │  • Local dev / webhook failures │                           │
│  └────────────────┬────────────────┘                           │
│                   │                                            │
│                   ▼                                            │
│        ┌──────────────────────┐                                │
│        │  Command Processor   │                                │
│        │  • Detect markers    │                                │
│        │  • Parse guidance    │                                │
│        │  • Route to handlers │                                │
│        └──────────┬───────────┘                                │
│                   │                                            │
│                   ▼                                            │
│           ┌─────────────────┐                                  │
│           │   Worker Pool   │                                  │
│           │  (Concurrency)  │                                  │
│           └────────┬────────┘                                  │
└────────────────────┼─────────────────────────────────────────
                        │
        ┌───────────────┼───────────────────┐
        │               │                   │
   ┌────▼─────┐  ┌──────▼──────┐    ┌─────▼─────┐
   │ Outline  │  │  AI Client  │    │   State   │
   │  Client  │  │  (OpenAI)   │    │   Store   │
   │          │  │             │    │ (SQLite)  │
   │ Rate     │  │ Rate        │    │ Q&A       │
   │ Limited  │  │ Limited     │    │ Tracking  │
   └────┬─────┘  └──────┬──────┘    └───────────┘
        │               │
        │               │
   ┌────▼─────────────┐ │
   │ Outline API      │ │
   │ /collections     │ │
   │ /documents       │ │
   │ /documents.move  │ │
   │ /comments.create │ │
   └──────────────────┘ │
                        │
                   ┌────▼──────────────┐
                   │ OpenAI-           │
                   │ Compatible        │
                   │ Endpoint          │
                   └───────────────────┘

    ┌────────────────────────────────────────────────┐
    │           Observability Layer                  │
    │  ┌──────────────┐  ┌──────────────┐            │
    │  │ Health Check │  │   Logging    │            │
    │  │   Server     │  │  (Zerolog)   │            │
    │  │ :8080/health │  │   Metrics    │            │
    │  └──────────────┘  └──────────────┘            │
    └────────────────────────────────────────────────┘
```

## Core Components

### 1. Configuration System
**Purpose**: Centralized configuration management

**Responsibilities**:
- Load YAML configuration with environment variable substitution
- Validate all settings on startup (API connectivity, collection existence)
- Provide strongly-typed configuration to all components

**Key Settings Groups**:
- Service config (concurrency, timeouts, ports)
- Outline API config (endpoint, key, excluded collection IDs, rate limits)
- AI config (endpoint, key, model, confidence thresholds)
- Feature flags (Q&A, commands, enhancements)
- Processing timings (poll intervals, retries)

### 2. Persistence Layer (SQLite)
**Purpose**: Track Q&A processing state to avoid duplicate answers

**Data Model**:
```
QuestionState:
  - id (PK)
  - question_hash (unique index)
  - document_id
  - question_text
  - processed_at
  - answer_delivered
  - last_error
  - retry_count

CommandLog (optional):
  - id (PK)
  - document_id
  - command_type
  - executed_at
  - status (success/failed)
  - error_message
```

**Interface Design**: Abstract storage interface for future extensibility (PostgreSQL, etc.)

**Why Simplified**: Since filing is command-driven (no polling/waiting), we only need to track Q&A state to prevent re-answering questions. Command logging is optional for audit purposes.

### 3. Rate Limiting Infrastructure
**Purpose**: Respect API rate limits for both Outline and AI services

**Implementation**:
- Token bucket algorithm using `golang.org/x/time/rate`
- Separate limiters for Outline API and AI API
- Configurable requests per minute
- Blocking wait when limit reached

### 4. Outline API Client
**Purpose**: All interactions with Outline workspace

**Key Methods**:
- `ListCollections()` - Fetch all collections with metadata
- `ListDocuments(collectionID)` - Get documents in collection
- `GetDocument(documentID)` - Fetch full document content
- `UpdateDocument(documentID, content)` - Modify document content
- `MoveDocument(documentID, collectionID)` - Relocate document
- `SearchDocuments(query)` - Keyword search across workspace
- `CreateComment(documentID, content, range)` - Add comments

**Error Handling**:
- Retry with exponential backoff for transient errors (5xx, timeouts)
- Respect 429 rate limits with backoff
- Permanent failure for 401 (auth), 404 (not found)
- Request timeouts (configurable, default 10s)

### 5. AI Client (OpenAI-compatible)
**Purpose**: Generate intelligent analysis and content

**Capabilities**:
- Configurable endpoint for any OpenAI-compatible API
- Structured prompts with JSON responses
- Circuit breaker pattern (pause after N consecutive failures)
- Token limit handling (truncate long documents)

**Request Types**:
1. **Document Classification**: Analyze content + optional user guidance → determine collection + confidence
   - User guidance influences AI decision: "engineering focused", "customer-facing", etc.
   - Must return alternatives when confidence is low
2. **Question Answering**: Question + context → answer with citations
3. **Content Enhancement**: Document → improved title/summary
4. **Related Documents**: Document → semantically similar documents

### 6. Taxonomy Builder
**Purpose**: Provide AI with workspace structure context

**Process**:
1. Fetch all collections (names, descriptions)
2. Sample recent documents from each collection (configurable max)
3. Build JSON representation for AI context
4. Cache with TTL (default 1 hour) to reduce API calls

**Output Format**:
```json
{
  "collections": [
    {
      "id": "...",
      "name": "Engineering",
      "description": "Technical docs and code",
      "sample_documents": ["API Design", "Database Schema", ...]
    }
  ]
}
```

### 7. Webhook Receiver
**Purpose**: Real-time event processing from Outline

**Status**: ✅ Fully supported with `documents.update` event
- [Webhook Documentation](https://docs.getoutline.com/s/guide/doc/webhooks-gB7HYhS6yq)
- Outline source code confirms `documents.update` is an AUDIT_EVENT
- Webhooks support subscription to specific events or patterns

**Key Events for Our Use Case**:
- `documents.update` - Document edited (PRIMARY - detects command markers and questions)
- `documents.create` - New document created (optional)
- `documents.publish` - Document published (optional)
- Can subscribe to patterns: `["documents."]` matches all document events

**Responsibilities**:
- HTTP endpoint to receive webhook events from Outline
- Validate webhook signatures using SHA-256 HMAC with shared secret
- Parse event payloads (event name, model attributes, actor ID, timestamp)
- Filter for `documents.update` and `documents.create` events
- Extract document ID and fetch full content
- Check for command markers (`/ai-file`, `/ai`, `/summarize`, `/enhance-title`, `/related`)
- Queue relevant documents for processing
- Must respond with HTTP 200 within 5 seconds

**Webhook Subscription Setup**:
```json
{
  "name": "Outline AI Assistant",
  "url": "https://your-service.com/webhooks",
  "secret": "your-webhook-secret",
  "events": ["documents.update", "documents.create"]
}
```

**Security**:
- Validate `Outline-Signature` header using SHA-256 HMAC
- Compare calculated signature with received signature
- Reject events with invalid or missing signatures
- Rate limit webhook endpoint to prevent abuse

**Reliability**:
- Webhooks auto-disable after 25 consecutive failures
- Failed deliveries retry with exponential backoff
- Email notifications on webhook failures
- Fallback polling mode for local development or if webhooks disabled

**Why Webhooks are Primary**: Real-time `documents.update` events eliminate polling overhead and provide immediate response to commands/questions

### 8. Worker Pool
**Purpose**: Concurrent document processing with controlled parallelism

**Design**:
- Goroutine-based workers (configurable max, default 3)
- Buffered channel as semaphore for concurrency control
- WaitGroup for tracking in-flight work
- Context-based cancellation for graceful shutdown

**Why Needed**: Process multiple documents simultaneously while respecting rate limits and system resources

## Feature Subsystems

### Command-Driven Filing System

**Flow**:
```
User adds /ai-file [optional guidance] to document
                ↓
    Command Detector identifies /ai-file
                ↓
      Submit to Worker Pool
                ↓
    Fetch Document Content + User Guidance
                ↓
      Get Taxonomy (cached)
                ↓
AI Analysis (collection + confidence, considering user guidance)
                ↓
            Confidence Check
                ↓
    ┌───────────┴───────────┐
    │                       │
High Confidence         Low Confidence
(>= threshold)          (< threshold)
    │                       │
    ▼                       ▼
Validate Collection    Convert /ai-file → ?ai-file
    ↓                       ↓
Generate Search Terms   Add Comment Explaining Uncertainty
    ↓                  (e.g., "Unclear if Engineering or Product")
Move to Collection          ↓
    ↓                   User Reviews
Remove /ai-file             ↓
    ↓              ┌────────┴────────┐
Add Success Comment│                 │
                   │                 │
            Update ?ai-file      Add New /ai-file
            to /ai-file          with guidance
            + guidance                │
                   │                  │
                   └──────────────────┘
                            ↓
                    Retry Filing (remove both markers on success)
```

**Key Decisions**:
- **On-demand activation**: User explicitly triggers filing with `/ai-file [guidance]` command
- **Optional guidance**: User can provide hints: `/ai-file engineering related` or `/ai-file customer-facing docs`
- **No waiting period**: Immediate processing when command is detected
- **Interactive feedback loop**: Low confidence converts to `?ai-file` with explanation
- **User refinement**: User can provide better guidance and retry
- **Dual marker cleanup**: Remove both `/ai-file` and `?ai-file` on successful filing
- **User control**: User decides when document is ready and can guide the AI
- Search terms improve future discoverability

### Q&A System

**Flow**:
```
Webhook: document.update → Detect /ai Command
   (or fallback polling)              ↓
                            Check if Already Answered
                                      ↓
                              Extract Question Text
                                      ↓
                    Extract Keywords → Search Workspace
                                      ↓
                        Fetch Top N Relevant Documents
                                      ↓
                Build Context (excerpts + links)
                                      ↓
                    AI: Question + Context → Answer
                                      ↓
                Format Answer with Source Citations
                                      ↓
                Create Comment on Question Line
                                      ↓
                Remove /ai Command from Document
                                      ↓
                    Track as Answered in State DB
```

**Why This Approach**:
- Works on **free-tier Outline** (no Business/Enterprise needed)
- Uses only free APIs: `/documents.search`, `/documents.info`, `/comments.create`
- Your own AI endpoint (any provider)
- Full control over behavior and costs
- Real-time responses via webhooks (or polling fallback)

**Question Detection**:
- Slash command: `/ai What is our deployment process?`
- `/ai How do we handle auth?`
- Detected via webhook events or fallback polling

### Command System

**Architecture**:
```
Polling Loop → Scan Documents for Command Markers
                              ↓
                    Command Detector
                              ↓
              Parse Command Type & Args
                              ↓
                    Route to Handler
                              ↓
        ┌──────────────┬────────────┬──────────────┬─────────────┐
        ▼              ▼            ▼              ▼             ▼
   /ai-file      /ai Handler  /summarize    /enhance-title  /related
        │              │            │              │             │
        └──────────────┴────────────┴──────────────┴─────────────┘
                              ↓
                Remove Command Marker from Document
                              ↓
                    Update State (optional)
```

**Event Detection Mechanism**:
- **Primary Method: Webhooks** (recommended)
  - Subscribe to `documents.update` events from Outline
  - Receive real-time notifications when documents are edited
  - Check updated document for command markers
  - Much more efficient than polling
  - Requires publicly accessible endpoint
- **Fallback: Polling** (if webhooks unavailable)
  - Periodically scan documents (configurable interval, default 30s)
  - Uses Outline's search API to find command markers
  - Useful for local development or restricted networks

**Command Markers**:
- `/ai [question]` - Ask question with workspace context
- `/ai-file [guidance]` - Active filing command (will be processed)
- `?ai-file [guidance]` - Uncertain filing marker (AI previously failed, needs user input)
- `/summarize` - Generate or update document summary
- `/enhance-title` - Improve document title
- `/related` - Find and link related documents
- When both `/ai-file` and `?ai-file` exist, process `/ai-file` and remove both on success

**Extensibility**: New commands added by implementing handler interface

**Available Commands**:
- `/ai [question]` - Ask question with workspace context
- `/ai-file [guidance]` - Analyze and file document to appropriate collection
  - Optional guidance helps AI: `/ai-file technical documentation`
  - Examples: `/ai-file`, `/ai-file customer-facing`, `/ai-file backend related`
- `/summarize` - Generate or update document summary (idempotent)
  - First run: Adds summary at top with hidden markers
  - Subsequent runs: Replaces existing summary
  - Tolerates minor user edits to summary
- `/enhance-title` - Improve vague titles
- `/related` - Find and link related documents

### Search Enhancement

**Capabilities**:

1. **Title Enhancement**:
   - Detect vague titles ("Notes", "Draft", "Untitled")
   - AI generates descriptive title based on content
   - Update document title if confidence high

2. **Summary Generation** (Idempotent):
   - AI creates 2-3 sentence summary
   - Added at top of document with markdown formatting
   - **Idempotent behavior**: Multiple `/summarize` commands cleanly replace previous summary
   - Uses hidden HTML comment markers to track AI-generated summaries:
     ```markdown
     <!-- AI-SUMMARY-START -->
     > **Summary**: AI-generated summary text here...
     <!-- AI-SUMMARY-END -->
     ```
   - **Replacement logic**:
     1. If markers exist: Replace content between markers
     2. If no markers but `> **Summary**:` format detected at top: Replace it and add markers
     3. If neither: Add new summary with markers
   - **Tolerates minor user edits**: User can edit summary text; markers preserved
   - **User can remove**: Deleting markers prevents replacement (user takes ownership)

3. **Search Terms** (Idempotent):
   - AI extracts key topics and concepts
   - Appended to document as markdown list
   - Improves Outline's built-in search
   - **Idempotent behavior**: Multiple operations cleanly replace previous search terms
   - Uses hidden HTML comment markers:
     ```markdown
     ---
     <!-- AI-SEARCH-TERMS-START -->
     **Search Terms**: term1, term2, term3
     <!-- AI-SEARCH-TERMS-END -->
     ```
   - **Replacement logic**:
     1. If markers exist: Replace content between markers
     2. If no markers but `**Search Terms**:` detected (with separator): Replace and add markers
     3. If neither: Append new search terms with markers
   - **Tolerates minor user edits**: User can add/remove terms; markers preserved
   - **User can remove**: Deleting markers prevents replacement (user takes ownership)

**Integration Point**: Can run as part of auto-filing pipeline or on-demand via command

## Observability & Operations

### Health Check Server
**Endpoints**:
- `GET /health` - Service status, last poll times (commands, Q&A), worker pool utilization
- `GET /metrics` - Prometheus-format metrics (optional): commands processed, questions answered, success/failure rates

**Purpose**: Enable monitoring, load balancer health checks, deployment orchestration

### Structured Logging
**Using**: `zerolog` for JSON-structured logs

**Key Log Events**:
- Command detection and execution (/ai-file, /ai, /summarize, etc.)
- Question detection and answering
- AI reasoning and confidence scores
- Document filing decisions and destinations
- Error details with context (correlation IDs)
- Rate limit events
- Processing durations

**Why Important**: Debugging, auditing, understanding AI decisions, tracking user interactions

### Graceful Shutdown
**Sequence**:
1. Receive SIGINT/SIGTERM signal
2. Stop accepting new work
3. Wait for in-flight processing (with timeout)
4. Flush state to database
5. Close HTTP server and connections

**Why Critical**: Prevent data loss, avoid partial updates, clean restarts

## Error Handling Strategy

### Error Categories

1. **Transient Errors** (retry with backoff):
   - Network timeouts
   - Rate limits (429)
   - Server errors (5xx)
   - AI service temporarily unavailable

2. **Permanent Errors** (mark failed, don't retry):
   - Authentication failures (401)
   - Document not found (404)
   - Invalid collection ID
   - Malformed AI responses after validation

3. **Partial Failures / User Feedback Needed**:
   - Document updated but move failed → retry move only
   - AI analysis low confidence → convert `/ai-file` to `?ai-file`, add comment with alternatives and guidance request (not an error, designed feedback loop)

### Retry Logic
- Exponential backoff: `base_delay * 2^retry_count`
- Max backoff cap (prevent infinite delays)
- Max retry count (default 3)
- After max retries: mark permanently failed, log for manual review

## Data Flow Examples

### Example 1: Filing a Document with /ai-file (High Confidence)
```
1. User creates doc: "PostgreSQL connection pooling best practices"
2. When ready, user adds line: "/ai-file"
3. Command polling loop detects /ai-file command
4. Submit to worker pool
5. Worker fetches document content and guidance (none in this case)
6. Worker gets cached taxonomy (Engineering, Product, Marketing, etc.)
7. Worker sends to AI:
   Prompt: "Given these collections, which fits this document?"
   Content: "PostgreSQL connection pooling..."
   User Guidance: (none)
8. AI responds:
   {
     "collection_id": "engineering_123",
     "confidence": 0.95,
     "reasoning": "Technical database content",
     "search_terms": ["PostgreSQL", "connection pooling", "performance"]
   }
9. Worker validates collection exists, confidence >= 0.7 ✓
10. Worker appends search terms to document
11. Worker moves document to Engineering collection
12. Worker removes /ai-file command from document
13. Worker adds comment: "✓ Filed to Engineering (confidence: 95%)"
```

### Example 2: Filing with Low Confidence - Interactive Refinement
```
1. User creates doc: "API documentation for mobile app"
2. User adds: "/ai-file"
3. Command polling detects /ai-file
4. Worker processes document
5. Worker sends to AI with taxonomy
6. AI responds:
   {
     "collection_id": "engineering_123",
     "confidence": 0.55,
     "reasoning": "Could be Engineering (API implementation) or Product (mobile features)",
     "alternatives": ["product_456"],
     "search_terms": ["API", "mobile", "documentation"]
   }
7. Worker sees confidence 0.55 < 0.7 threshold ✗
8. Worker converts "/ai-file" → "?ai-file"
9. Worker adds comment:
   "⚠️ Unable to file with confidence. Uncertain between:
    - Engineering (API implementation details)
    - Product (mobile app features)

    To help me decide:
    - Edit this line to: /ai-file engineering focus
    - Or add a new line: /ai-file product documentation

    [AI Confidence: 55%]"
10. User reviews, updates line: "?ai-file" → "/ai-file backend API implementation"
11. Next polling cycle detects new /ai-file with guidance
12. Worker reprocesses with guidance: "backend API implementation"
13. AI responds:
    {
      "collection_id": "engineering_123",
      "confidence": 0.92,
      "reasoning": "Backend API implementation clearly belongs in Engineering",
      "search_terms": ["API", "mobile", "backend", "documentation"]
    }
14. Worker validates confidence >= 0.7 ✓
15. Worker files to Engineering
16. Worker removes BOTH "/ai-file" and "?ai-file" markers (if both exist)
17. Worker adds comment: "✓ Filed to Engineering (confidence: 92%) - Thank you for the guidance!"
```

### Example 3: Filing with Guidance from the Start
```
1. User creates doc: "Customer onboarding process"
2. User knows this could be ambiguous, adds: "/ai-file customer success focused"
3. Command polling detects /ai-file
4. Worker fetches content and guidance: "customer success focused"
5. AI analyzes with user hint
6. AI responds:
   {
     "collection_id": "customer_success_789",
     "confidence": 0.88,
     "reasoning": "User indicated customer success focus, content matches",
     "search_terms": ["customer", "onboarding", "process"]
   }
7. High confidence ✓ - files successfully
8. Worker adds comment: "✓ Filed to Customer Success (confidence: 88%) - Used your guidance"
```

### Example 4: Answering a Question
```
1. User adds to document: "/ai What is our API rate limit policy?"
2. Webhook triggers on document.update
3. Command detector finds /ai command
4. Extract question: "What is our API rate limit policy?"
5. Check if already answered (hash of question + doc ID) - not found
6. Extract keywords: ["API", "rate limit", "policy"]
7. Search workspace for relevant documents
8. Find top 5 matches:
   - "API Design Guidelines" (excerpt about rate limits)
   - "Backend Architecture" (rate limiter implementation)
   - "API Terms of Service" (rate limit tiers)
9. Build context with excerpts + links
10. Send to AI:
    Question: "What is our API rate limit policy?"
    Context: [excerpts from 5 documents]
11. AI generates answer:
    "Our API uses a tiered rate limiting system:
     - Free tier: 100 requests/hour
     - Pro tier: 1000 requests/hour
     See [API Design Guidelines](outline://doc/xyz) for details."
12. Create comment on /ai line with answer
13. Remove "/ai" command from document
14. Track question as answered in State DB
```

### Example 5: Idempotent /summarize Command
```
INITIAL STATE:
Document title: "Database Migration Strategy"
Content: [Long technical content about database migrations...]

FIRST RUN:
1. User adds: "/summarize"
2. Webhook triggers, detects /summarize
3. Worker fetches document content
4. AI generates summary: "This document outlines our approach to database migrations..."
5. Worker checks for existing summary markers: None found
6. Worker adds summary at top:
   <!-- AI-SUMMARY-START -->
   > **Summary**: This document outlines our approach to database migrations
   > using zero-downtime techniques and automated rollback procedures.
   <!-- AI-SUMMARY-END -->

   [Rest of document content...]
7. Worker removes /summarize command
8. Document updated

SECOND RUN (document content changed):
1. User edits document, adds more content about rollback procedures
2. User adds: "/summarize" (wants updated summary)
3. Webhook triggers
4. Worker fetches updated document content
5. AI generates new summary: "This document describes our database migration strategy..."
6. Worker finds existing summary markers
7. Worker REPLACES content between markers:
   <!-- AI-SUMMARY-START -->
   > **Summary**: This document describes our database migration strategy
   > with emphasis on zero-downtime deployments and comprehensive rollback procedures.
   <!-- AI-SUMMARY-END -->

   [Rest of document content...]
8. Worker removes /summarize command
9. No duplicate summaries - clean replacement

THIRD RUN (user edited summary slightly):
1. User manually edited summary: "...with emphasis on zero-downtime and automated rollbacks"
2. User adds: "/summarize" (after more content changes)
3. Worker detects markers still exist
4. AI generates fresh summary based on all current content
5. Worker replaces content between markers (user's edits overwritten)
6. Result: Clean, updated summary reflecting current document state

USER TAKES OWNERSHIP:
1. User likes the summary but wants to customize it significantly
2. User removes the <!-- AI-SUMMARY-START --> and <!-- AI-SUMMARY-END --> markers
3. User edits summary extensively
4. Later, user adds /summarize to update search terms
5. Worker finds NO summary markers
6. Worker detects `> **Summary**:` format at top
7. Worker could either:
   a) Skip summary update (no markers = user ownership)
   b) Replace and re-add markers (configurable behavior)
   Default: Skip to respect user ownership
```

## Security & Best Practices

### Security Considerations
- Never log API keys (mask in logs)
- Load secrets from environment variables
- Validate and sanitize content before AI processing
- Maximum content length limits
- HTTPS for all API communication
- Validate AI responses to prevent injection

### Performance Optimizations
- Taxonomy caching (reduce Outline API calls)
- Worker pool concurrency (configurable parallelism)
- Rate limiting (respect API limits)
- Incremental processing (only new/changed documents)
- Optional semantic search caching (vector embeddings)

### Operational Considerations
- Dry-run mode for testing configuration
- State persistence across restarts
- Health checks for monitoring
- Structured logging for debugging
- Configurable timeouts and retries
- Graceful degradation (if AI unavailable, skip non-critical features)

## Technology Stack

- **Language**: Go 1.21+
- **Database**: SQLite (embedded) with GORM
- **HTTP Client**: Standard library with rate limiting
- **AI Client**: `sashabaranov/go-openai`
- **Configuration**: `spf13/viper`
- **Logging**: `rs/zerolog`
- **Rate Limiting**: `golang.org/x/time/rate`

## Deployment Options

1. **Standalone Binary**: Run on VM or bare metal
2. **Docker Container**: Containerized deployment
3. **Kubernetes**: Deploy as Deployment with persistent volume for SQLite
4. **Systemd Service**: Run as system service with auto-restart

## Configuration Example Structure

```yaml
service:
  max_concurrent_workers: 3
  health_check_port: 8080
  webhook_port: 8081
  public_url: "https://your-service.com"  # For webhook registration
  dry_run: false

outline:
  api_endpoint: "https://app.getoutline.com/api"
  api_key: "${OUTLINE_API_KEY}"
  webhook_secret: "${OUTLINE_WEBHOOK_SECRET}"  # For signature validation
  excluded_collection_ids: []  # Collections to exclude from filing destinations
  rate_limit_per_minute: 100

webhooks:
  enabled: true
  events: ["documents.update", "documents.create"]
  signature_validation: true

  # Fallback polling if webhooks fail or unavailable
  fallback_polling:
    enabled: true
    interval: 60s  # Less frequent since webhooks are primary

ai:
  endpoint: "https://api.openai.com/v1"
  api_key: "${OPENAI_API_KEY}"
  model: "gpt-4"
  confidence_threshold: 0.7
  request_timeout: 30s

processing:
  max_retries: 3
  retry_backoff_base: 30s
  retry_backoff_max: 5m

taxonomy:
  cache_ttl: 1h
  include_sample_documents: true
  max_samples_per_collection: 5

qna:
  enabled: true
  max_context_documents: 5
  answer_method: "comment"  # "comment" or "inline"

enhancement:
  enabled: true
  enhance_titles: true
  add_summaries: true
  idempotent_updates: true         # Use markers for clean replacement on re-run
  respect_user_ownership: true     # Skip update if user removes markers

commands:
  enabled: true
  available: ["/ai", "/ai-file", "/summarize", "/enhance-title", "/related"]
  filing:
    include_alternatives: true     # Show alternative collections in low-confidence comment
    max_alternatives: 3            # Maximum alternative collections to suggest
    success_comment: true          # Add comment on successful filing
    uncertainty_comment: true      # Add comment explaining low confidence
  summarize:
    use_markers: true              # Add HTML comment markers for idempotency
    respect_no_markers: true       # Skip if markers removed (user ownership)
    detect_existing_format: true   # Try to detect existing summaries without markers
  search_terms:
    use_markers: true              # Add HTML comment markers for idempotency
    respect_no_markers: true       # Skip if markers removed (user ownership)

logging:
  level: "info"
  format: "json"
  output: "stdout"
```

## Key Design Decisions

1. **Go Language**: Excellent concurrency, single binary deployment, strong typing
2. **SQLite**: Embedded, no external dependencies, sufficient for single-instance deployment
3. **Command-Driven Filing**: User explicitly triggers via `/ai-file [guidance]` instead of automatic polling
   - Gives user control over when documents are ready to file
   - Optional guidance parameter helps AI make better decisions
   - Reduces unnecessary API calls and processing
   - No complex wait-period logic needed
4. **Interactive Guidance Loop** (`/ai-file` ↔ `?ai-file`):
   - When AI confidence is low, convert command to question marker
   - Explain uncertainty with specific alternatives
   - User can refine guidance and retry
   - **Benefits**:
     - Transparency: User sees AI's uncertainty
     - Iterative improvement: User provides hints to resolve ambiguity
     - No silent failures: Documents don't disappear to wrong collections
     - Educational: User learns what makes filing ambiguous
   - **Better than**: Guessing wrong destination or requiring manual filing
5. **Dual Marker Cleanup**: Remove both `/ai-file` and `?ai-file` on success
   - Prevents re-processing
   - Clean document after filing
   - Clear indication that filing completed
6. **Webhook-First Architecture**: Real-time event processing via Outline webhooks
   - Subscribe to `documents.update` and `documents.create` events
   - Immediate response when users add commands or questions
   - Eliminates polling overhead (reduced API calls by 99%)
   - Fallback polling mode for local development or if webhooks unavailable
   - Signature validation ensures only legitimate Outline events processed
7. **Comment-based Q&A**: Non-invasive, clearly AI-generated, user can resolve/delete
8. **Rate Limiting**: Prevents API throttling, ensures reliability
9. **Worker Pool**: Controlled concurrency, prevents resource exhaustion
10. **Minimal State Persistence**: Only track Q&A to avoid duplicates; no complex document state machine
11. **OpenAI-compatible API**: Flexibility to use any provider (OpenAI, Claude, local models, Ollama)

## Future Enhancements (Out of Scope for v1)

- Vector database integration for semantic search (Chroma, Qdrant)
- Multi-instance deployment with distributed locks (Redis, etcd)
- PostgreSQL support for high-scale deployments
- Webhook support (if Outline adds it)
- Web UI for configuration and monitoring
- Document change detection (update summaries when content changes)
- Custom AI prompt templates per collection
- User-specific preferences (per-user wait times, confidence thresholds)

---

This high-level design provides a comprehensive blueprint for implementation while maintaining flexibility for adjustments based on real-world usage and feedback.
